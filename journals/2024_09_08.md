# 关于 [[Python]] Gemini SDK 的使用
	- Gemini是谷歌的AI大模型，多模态，能以图像、音频作为输入，提供了python SDK和一些文档，学习一下，研究能否集成到自己的工作流中。参考[google-gemini/cookbook](https://github.com/google-gemini/cookbook)。
	- 安装SDK使用：
	- ```
	  pip install google-generativeai
	  ```
	- Hello World例子，文档建议把key存到环境变量里：
	- ```python
	  import os
	  import google.generativeai as genai
	  
	  # SDK不会直接走系统代理，但会从环境变量里走
	  PROXY_URL = 'http://127.0.0.1:21001'
	  os.environ['http_proxy'] = PROXY_URL 
	  os.environ['HTTP_PROXY'] = PROXY_URL
	  os.environ['https_proxy'] = PROXY_URL
	  os.environ['HTTPS_PROXY'] = PROXY_URL
	  
	  genai.configure(api_key=你的KEY)
	  model = genai.GenerativeModel('models/gemini-1.5-flash')
	  response = model.generate_content("给我一个Python快排实现")
	  print(response.text)
	  ```
	- 大语言模型（LLM）中，输入（即使是非文字数据）和输出都以**token**为计量，token是这样一种粒度，它大于单个unicode字符，但小于一个单词。LLM有一个**上下文窗口**——输入和输出最多能包含多少个token（或者说，LLM同一时间能记住多少token）。Gemini-1.5-flash最多支持1M的上下文窗口。
	- 上面使用的`model.generate_content`方法是没有记忆的，每次都是开启新对话，如果想让对话保持，可以使用`model.start_chat`方法（创建时可以给定一些初始的对话），这会创建一个session去记录对话。
	- ```python
	  chat = model.start_chat(history=[{'role':'user', 'parts':'Hi my name is Bob'},  {'role':'model', 'parts':'Hi Bob!'}])
	  print(model.count_tokens(chat.history)) # 10 
	  response = chat.send_message('tell me a joke')
	  print(response.text)
	  print(model.count_tokens(chat.history)) # 46
	  response = chat.send_message('tell me another joke')
	  print(response.text)
	  print(model.count_tokens(chat.history)) # 87
	  ```
	- Gemini是多模态的，文件可以直接传给Gemini，也可以先用文件API把它上传给谷歌后续再使用。
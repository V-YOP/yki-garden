# 关于 [[Python]] Gemini SDK 的使用
	- Gemini是谷歌的AI大模型，多模态，能以图像、音频作为输入，提供了python SDK和一些文档，学习一下，研究能否集成到自己的工作流中。参考[google-gemini/cookbook](https://github.com/google-gemini/cookbook)。
	- **安装**SDK使用：
	- ```
	  pip install google-generativeai
	  ```
	- **Hello World**，文档建议把key存到环境变量里：
	- ```python
	  import os
	  import google.generativeai as genai
	  
	  # SDK不会直接走系统代理，但会从环境变量里走
	  PROXY_URL = 'http://127.0.0.1:21001'
	  os.environ['http_proxy'] = PROXY_URL 
	  os.environ['HTTP_PROXY'] = PROXY_URL
	  os.environ['https_proxy'] = PROXY_URL
	  os.environ['HTTPS_PROXY'] = PROXY_URL
	  
	  genai.configure(api_key=你的KEY)
	  model = genai.GenerativeModel('models/gemini-1.5-flash')
	  response = model.generate_content("给我一个Python快排实现")
	  print(response.text)
	  ```
	- 大语言模型（LLM）中，输入（即使是非文字数据）和输出都以**token**为计量，token是这样一种粒度，它大于单个unicode字符，但小于一个单词。LLM有一个**上下文窗口**——输入和输出最多能包含多少个token（或者说，LLM同一时间能记住多少token）。Gemini-1.5-flash最多支持1M的上下文窗口。
	- **ChatSession**，上面使用的`model.generate_content`方法是没有记忆的，每次都是开启新对话，如果想让对话保持，可以使用`model.start_chat`方法（创建时可以给定一些初始的对话），这会创建一个session去记录对话。
	- ```python
	  chat = model.start_chat(history=[{'role':'user', 'parts':'Hi my name is Bob'},  {'role':'model', 'parts':'Hi Bob!'}])
	  print(model.count_tokens(chat.history)) # 10 
	  response = chat.send_message('tell me a joke')
	  print(response.text)
	  print(model.count_tokens(chat.history)) # 46
	  response = chat.send_message('tell me another joke')
	  print(response.text)
	  print(model.count_tokens(chat.history)) # 87
	  ```
	- **多模态**，Gemini是多模态的（只考虑图像），图像可以用PIL打开后直接传给Gemini，也可以先用文件API把它上传给谷歌后续再使用，文件只能保存48小时。文件可以是任何类型的文件，包括文本，图像，音频视频等。上传文件时，能提供文件的展示名称以及MIME类型。
	- ```python
	  # 通过文件API上传
	  file = genai.upload_file('img004.jpg')
	  same_file = genai.get_file(file.name) # 文件的唯一标识符是name字段，可以重用
	  res = model.generate_content(['这张图描述了什么', file])
	  
	  # 直接传PIL对象
	  img = Image.open('img004.jpg')
	  res = model.generate_content(['这张图描述了什么', img])
	  ```
	- **JSON模式**，模型，或者某次对话时，可以配置模型使用json模式去进行响应。可以在prompt中，或者**直接通过python类型**去定义返回格式。
	- ```python
	  # 直接整个配置模型返回json
	  model = genai.GenerativeModel('models/gemini-1.5-flash', generation_config={"response_mime_type": "application/json"})
	  res = model.generate_content("""\
	  列举出一些常见的蛋糕类型，使用下面给定的typescript格式作为返回格式
	  type Cake = {
	      name: string,
	      description: string
	  }
	  type Response = Cake[]
	  """)
	  
	  # 某次对话时配置返回json，并且指定返回值格式
	  
	  ```